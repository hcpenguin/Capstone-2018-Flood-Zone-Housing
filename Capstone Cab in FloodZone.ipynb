{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import statsmodels.formula.api as smf    # for OLS regression\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import urllib \n",
    "import scipy.stats\n",
    "import os\n",
    "import sys\n",
    "%pylab inline\n",
    "\n",
    "#importing geopandas read to plot geographical information\n",
    "import geopandas as gpd\n",
    "#importing fiona to handle geographical coordinates\n",
    "import fiona\n",
    "#import shapely to handle geographical shapes\n",
    "import shapely\n",
    "import urllib.request\n",
    "import gzip\n",
    "from shapely.geometry import Point\n",
    "from geopandas.tools import sjoin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yellow Cab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(17,19):\n",
    "    for i in range(1,13):\n",
    "        os.system('curl -O https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_' + str(2000+year) + '-' + str(i).zfill(2) + '.csv')\n",
    "        os.system('mv yellow_tripdata_'+ str(2000+year) + '-' + str(i).zfill(2) + '.csv ' + '/Volumes/MACExt/FloodHousing/yellowcab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"curl -O https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2009-02.csv\")\n",
    "os.system(\"mv yellow_tripdata_2009-02.csv \" + os.getenv(\"PUIDATA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "#path = r'Data/FHV2015'                     # use your path\n",
    "all_files = glob.glob(os.path.join(\"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "#concatenated_df   =  pd.concat(df_from_each_file, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'init': 'epsg:4269'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census = gpd.GeoDataFrame.from_file('cb_2016_36_tract_500k/cb_2016_36_tract_500k.shp')\n",
    "census.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Floodzone FIRM07 and PFIRM15 Census Tracts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodzone07 = pd.read_csv('/Users/cihe/Documents/CUSPClassAssignments/Capstone/Code/pluto_FIRM07.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodzone07.drop([u'Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodzone07.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodzone07.CT2010 = floodzone07.CT2010*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "floodzone07.CT2010 = floodzone07.CT2010.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodzone07.CT2010 = floodzone07.CT2010.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodzone07.CT2010 = floodzone07.CT2010.astype('str')\n",
    "floodzone07.CT2010 = floodzone07.CT2010.str.zfill(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodzone07.CT2010 = floodzone07.CT2010.astype('int')\n",
    "floodzone07.CT2010 = floodzone07.CT2010 + floodzone07.Boro*1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodzone07.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodzone07.rename(columns={'CT2010':'GEOID'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodzone07.GEOID = floodzone07.GEOID.astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#floodzone07.to_csv('floodzone07_wGEOID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_floodzone07 = gpd.GeoDataFrame.merge(census, floodzone07, how='inner', on='GEOID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_floodzone07.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodzone15 = pd.read_csv('/Users/cihe/Documents/CUSPClassAssignments/Capstone/Code/pluto_PFIRM15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodzone15.drop([u'Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodzone15.CT2010 = floodzone15.CT2010*100\n",
    "floodzone15.CT2010 = floodzone15.CT2010.fillna(0)\n",
    "floodzone15.CT2010 = floodzone15.CT2010.astype('int')\n",
    "floodzone15.CT2010 = floodzone15.CT2010.astype('str')\n",
    "floodzone15.CT2010 = floodzone15.CT2010.str.zfill(6)\n",
    "floodzone15.CT2010 = floodzone15.CT2010.astype('int')\n",
    "floodzone15.CT2010 = floodzone15.CT2010 + floodzone15.Boro*1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodzone15.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodzone15.rename(columns={'CT2010':'GEOID'}, inplace=True)\n",
    "floodzone15.GEOID = floodzone15.GEOID.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#floodzone15.to_csv('floodzone15_wGEOID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_floodzone15 = gpd.GeoDataFrame.merge(census, floodzone15, how='inner', on='GEOID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_floodzone15.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Lat Lon Info to  GeoPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(all_files[12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(' pickup_datetime'  in df.columns) & (' pickup_longitude' in df.columns) & (' pickup_latitude' in df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(all_files)):\n",
    "for i in range(19,24):\n",
    "    df = pd.read_csv(all_files[i])\n",
    "    #downsample\n",
    "    df = df.sample(frac=0.02, replace=True)\n",
    "    if ((' pickup_datetime'  in df.columns) & (' pickup_longitude' in df.columns) & (' pickup_latitude' in df.columns)):\n",
    "        df = df[[' pickup_datetime', ' pickup_longitude', ' pickup_latitude']]\n",
    "        df[' pickup_latitude'].astype('float')\n",
    "        df[' pickup_longitude'].astype('float')\n",
    "        df['geometry'] = df.apply(lambda z: Point(z[' pickup_longitude'], z[' pickup_latitude']), axis=1)\n",
    "    else:\n",
    "        df = df[['pickup_datetime', 'pickup_longitude', 'pickup_latitude']]\n",
    "        df.pickup_latitude.astype('float')\n",
    "        df.pickup_longitude.astype('float')\n",
    "        df['geometry'] = df.apply(lambda z: Point(z['pickup_longitude'], z['pickup_latitude']), axis=1)\n",
    "    pickup_point = df.geometry\n",
    "    pickup_point = gpd.GeoDataFrame(pickup_point)\n",
    "    pickup_point.crs = tract_floodzone07.crs\n",
    "    pointInPolys_07_pickup = sjoin(pickup_point, tract_floodzone07, how='left')\n",
    "    FIRM07_pickup = pointInPolys_07_pickup.groupby('GEOID').count()\n",
    "    FIRM07_pickup.reset_index(inplace=True)\n",
    "    FIRM07_pickup = FIRM07_pickup[['GEOID','index_right']]\n",
    "    FIRM07_pickup.rename(columns={'index_right':'TAXI_PICKUP'}, inplace=True)\n",
    "    floodzone07_taxi = floodzone07.merge(FIRM07_pickup, how='inner', on='GEOID')\n",
    "    floodzone07_taxi.to_csv('floodzone07_taxi' + str(i) + '.csv')\n",
    "    \n",
    "    pointInPolys_15_pickup = sjoin(pickup_point, tract_floodzone15, how='left')\n",
    "    PFIRM15_pickup = pointInPolys_15_pickup.groupby('GEOID').count()\n",
    "    PFIRM15_pickup.reset_index(inplace=True)\n",
    "    PFIRM15_pickup = PFIRM15_pickup[['GEOID','index_right']]\n",
    "    PFIRM15_pickup.rename(columns={'index_right':'TAXI_PICKUP'}, inplace=True)\n",
    "    floodzone15_taxi = floodzone15.merge(PFIRM15_pickup, how='inner', on='GEOID')\n",
    "    floodzone15_taxi.to_csv('floodzone15_taxi' + str(i) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(all_files[0])\n",
    "df = df[['pickup_datetime', 'dropoff_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', \n",
    "         'dropoff_latitude']]\n",
    "df.pickup_latitude.astype('float')\n",
    "df.pickup_longitude.astype('float')\n",
    "df.dropoff_longitude.astype('float')\n",
    "df.dropoff_latitude.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['geometry1'] = df.apply(lambda z: Point(z['pickup_longitude'], z['pickup_latitude']), axis=1)\n",
    "pickup_point = df.geometry1\n",
    "pickup_point = gpd.GeoDataFrame(pickup_point)\n",
    "df['geometry2'] = df.apply(lambda z: Point(z['dropoff_longitude'], z['dropoff_latitude']), axis=1)\n",
    "dropoff_point = df.geometry2\n",
    "dropoff_point = gpd.GeoDataFrame(dropoff_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_point.crs = tract_floodzone07.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_point.rename(columns={'geometry1':'geometry'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_floodzone07.drop([u'Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointInPolys_07_pickup = sjoin(pickup_point, tract_floodzone07, how='left')\n",
    "FIRM07_pickup = pointInPolys_07_pickup.groupby('GEOID').sum()\n",
    "FIRM07_pickup.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRM07_pickup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_point.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(concatenated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df.dropna(axis=0, inplace=True)\n",
    "concatenated_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df.to_csv('Data/FHV2015/FHV2015_concat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#init from concat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV = pd.read_csv('Data/FHV2015/FHV2015_concat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV.reset_index(inplace=True)\n",
    "FHV.rename(columns={'index':'dispatching_number'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV.drop([u'Unnamed: 0', u'Dispatching_base_num'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV.to_csv('Data/FHV/FHV2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# project taxi zone to tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#census = gpd.GeoDataFrame.from_file('Data/cb_2016_36_tract_500k/cb_2016_36_tract_500k.shp')\n",
    "#census.head()\n",
    "\n",
    "NYCcensus = gpd.GeoDataFrame.from_file('Data/nyc tracts/nyu_2451_34513.shp')\n",
    "NYCcensus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYCcensus.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYCcensus.plot(facecolor='w',edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxizone = gpd.GeoDataFrame.from_file('Data/taxi zone/taxi_zones.shp')\n",
    "taxizone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxizone.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxizone.plot(figsize(10,10),facecolor='w',edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYCcensus.crs = taxizone.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonecombined = gpd.sjoin(NYCcensus,taxizone,how=\"left\",op=\"intersects\")\n",
    "zonecombined.fillna(0, inplace = True)\n",
    "zonecombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonecombined = zonecombined[zonecombined.index_right>0]\n",
    "zonecombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_of_intersection(base, taxi):\n",
    "    return base['geometry'].intersection(taxi['geometry'].iloc[int(base['index_right'])]).area\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonecombined['intersection_size'] = zonecombined.apply(lambda row : \n",
    "                                       get_size_of_intersection(row, taxizone), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonecombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonecombined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonecombined.drop([u'statefp', u'countyfp', u'name', u'namelsad', u'mtfcc',\n",
    "       u'funcstat', u'aland', u'awater', u'OBJECTID'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonecombined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxizone['area'] = taxizone.geometry.area\n",
    "taxizone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zonecombined.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonecombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zonecombined['taxizone_area']=0\n",
    "for k in range(len(zonecombined)):\n",
    "        zonecombined['taxizone_area'][k] = taxizone['area'][int(zonecombined['LocationID'][k]-1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonecombined.rename(columns={\"index\": \"zone_percentage\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zonecombined['zone_percentage']=zonecombined['intersection_size']/zonecombined['taxizone_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonecombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonecombined.to_csv('Data/combinezonefinal.csv', sep=',', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get each tracts trip quantities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#format cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV = pd.read_csv('Data/FHV/FHV2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV['Pickup_date'] = pd.to_datetime(FHV['Pickup_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV.Pickup_date[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV.drop([u'Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV.to_csv('Data/FHV/FHV2016cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#use cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV = pd.read_csv('Data/FHV/FHV2016cleaned.csv')\n",
    "FHV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV_quan = FHV.groupby(['locationID']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV_quan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV_quan.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV_quan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV_quan.rename(columns={'Pickup_date':'pickup'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV_quan.drop([u'Pickup_date'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV_quan.drop([u'index'], axis = 1, inplace = True)\n",
    "FHV_quan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV_quan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV_quan.rename(columns={'locationID':'LocationID'}, inplace=True)\n",
    "FHV_quan.to_csv('Data/FHV2015/FHV_quan.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find FHV picks for each tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intracts = pd.read_csv('Data/combinezonefinal.csv')\n",
    "intracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intracts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV_quan = pd.read_csv('Data/FHV/FHV_quan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV_quan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(FHV_quan.LocationID[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(intracts.LocationID[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intractsmerge = pd.merge(intracts, FHV_quan, how='inner', on='LocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intractsmerge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intractsmerge.rename(columns={'Unnamed: 0':'pickups_intract'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intractsmerge['pickups_intract'] = intractsmerge.zone_percentage*intractsmerge.pickup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = intractsmerge.groupby(['geoid']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat.reset_index(inplace=True)\n",
    "heat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat.drop([ u'zone_percentage', u'tractce',u'intptlat', u'intptlon',\n",
    "       u'index_right', u'Shape_Leng', u'Shape_Area', u'LocationID',\n",
    "       u'intersection_size', u'taxizone_area', u'pickup'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heat.drop([u'index',], axis = 1, inplace = True)\n",
    "heat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat.to_csv('Data/FHV2015/pickups2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot heatmap on census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYCcensus = gpd.GeoDataFrame.from_file('Data/nyc tracts/nyu_2451_34513.shp')\n",
    "NYCcensus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYCcensus['geoid'] = NYCcensus['geoid'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYCcensusmerge = gpd.GeoDataFrame.merge(NYCcensus, heat, how='inner', on='geoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYCcensusmerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYCcensusmerge.plot(column='pickups_intract',cmap='OrRd', scheme='quantiles',facecolor='w',edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYCcensusmergeFHV = NYCcensusmerge[['geoid','pickups_intract']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYCcensusmergeFHV.to_csv('Data/FHV/NYCcensusmergeFHV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import choroplethNYC as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find latlon from address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import json\n",
    "\n",
    "googleGeocodeUrl = 'http://maps.googleapis.com/maps/api/geocode/json?'\n",
    "\n",
    "def get_coordinates(query, from_sensor=False):\n",
    "    query = query.encode('utf-8')\n",
    "    params = \"address={}\".format(\n",
    "            query,\n",
    "#        'sensor': \"true\" if from_sensor else \"false\"\n",
    "        )\n",
    "    url = \"{googleGeocodeUrl}{params}\".format(googleGeocodeUrl=googleGeocodeUrl, params=params)\n",
    "    response = requests.get(url)\n",
    "    if response.json()['results']:\n",
    "        location = response.json()['results'][0]['geometry']['location']\n",
    "        latitude, longitude = location['lat'], location['lng']\n",
    "#        print (query, latitude, longitude)\n",
    "    else:\n",
    "        latitude, longitude = None, None\n",
    "        print (query, \"<no results>\")\n",
    "    return latitude, longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '2031 spring cedar ln, houston'\n",
    "get_coordinates(a)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newbuildings = pd.read_excel(\"Data/brooklynnewbuildings.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(newbuildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in newbuildings.index:\n",
    "    newbuildings.loc[i,'lat'] = get_coordinates(newbuildings.loc[i,'full_address'])[0]\n",
    "    newbuildings.loc[i,'lon'] = get_coordinates(newbuildings.loc[i,'full_address'])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newbuildings.to_csv('newbuildingsloc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
